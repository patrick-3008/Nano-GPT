Nano-GPT
========

Nano-GPT is a minimal implementation of a GPT (Generative Pre-trained Transformer) model, designed to work with the `shakespeare_dataset.txt` dataset. This project is a simplified version of larger GPT models and demonstrates the basic functionality of text generation using neural networks.

Dataset
-------

The model is trained using the **Shakespeare dataset**, which is a collection of Shakespeare’s works. It can be used to generate text in a similar style to Shakespeare’s writing.

*   **Dataset file**: `shakespeare_dataset.txt`
*   **Source**: This dataset can be obtained from various public domain repositories, such as Project Gutenberg.

Installation
------------

To get started with Nano-GPT, clone this repository and install the necessary dependencies:

        git clone https://github.com/your-username/Nano-GPT.git
        cd Nano-GPT
        pip install -r requirements.txt
        
    

Usage
-----

To train the model on the Shakespeare dataset just run the python notebook  
    
After training, you can generate text using the trained model        

You can customize parameters like the length of the generated text, the temperature (for randomness), and more.

Acknowledgements
----------------

This project uses the approach outlined in Andrej Karpathy's blog post and tutorials on building simple neural networks, particularly his work with character-level language models.

*   **Andrej Karpathy**: Special thanks to Andrej Karpathy for his inspiring work on neural networks and GPT models. His blog and teachings were pivotal in the development of this project.

email: patricknaashat@yahoo.com

Enjoy using Todoey!
